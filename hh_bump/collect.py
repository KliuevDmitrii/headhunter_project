import csv
from datetime import datetime, timedelta, timezone
from pathlib import Path

from hh_bump.config import Settings
from hh_bump.api import HHApi
from hh_bump.auth import get_stored_access_token
from hh_bump.notifier import TelegramNotifier


def parse_dt(value: str) -> datetime:
    """HH –æ—Ç–¥–∞—ë—Ç ISO-–¥–∞—Ç—É ‚Äî –ø—Ä–∏–≤–æ–¥–∏–º –∫ datetime"""
    return datetime.fromisoformat(value.replace("Z", "+00:00"))


def main():
    s = Settings()
    notifier = TelegramNotifier()

    token = get_stored_access_token()
    if not token:
        notifier.send("‚ùå –ù–µ—Ç access_token –¥–ª—è —Å–±–æ—Ä–∞ –≤–∞–∫–∞–Ω—Å–∏–π")
        return

    api = HHApi(
        api_base=s.api_base,
        token=token,
        app_name=s.app_name,
    )

    output_file = Path(s.vacancies_output_file)

    # üîë –∫–ª—é—á = url, –∑–Ω–∞—á–µ–Ω–∏–µ = –≤–∞–∫–∞–Ω—Å–∏—è
    –≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url: dict[str, dict] = {}

    searches_done = 0

    date_from = (
        datetime.now(timezone.utc) - timedelta(days=s.days_back)
    ).strftime("%Y-%m-%dT%H:%M:%S")

    exclude_keywords = s.exclude_keywords
    exclude_company_keywords = s.exclude_company_keywords

    for text in s.search_texts:
        print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ –∫–ª—é—á—É: ¬´{text}¬ª")

        for area in s.areas:
            for page in range(s.max_pages):
                if searches_done >= s.max_searches_per_run:
                    break

                try:
                    items = api.search_vacancies(
                        text=text,
                        area=area,
                        per_page=s.per_page,
                        page=page,
                        date_from=date_from,
                    )
                    searches_done += 1
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ [{text}, area={area}, page={page}]: {e}")
                    continue

                if not items:
                    break

                for v in items:
                    name = v.get("name") or ""
                    vacancy_name = name.lower()

                    company = v.get("employer", {}).get("name") or ""
                    company_name = company.lower()

                    url = v.get("alternate_url")
                    published_at = v.get("published_at")

                    if not url or not published_at:
                        continue

                    # ‚ùå —Ñ–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –≤–∞–∫–∞–Ω—Å–∏–∏
                    if any(x in vacancy_name for x in exclude_keywords):
                        continue

                    # ‚ùå —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏
                    if any(x in company_name for x in exclude_company_keywords):
                        continue

                    new_dt = parse_dt(published_at)

                    vacancy_data = {
                        "id": v.get("id"),
                        "name": name,
                        "company": company,
                        "area": v.get("area", {}).get("name"),
                        "published_at": published_at,
                        "url": url,
                    }

                    # üîÅ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ URL
                    if url in –≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url:
                        old_dt = parse_dt(–≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url[url]["published_at"])
                        if new_dt > old_dt:
                            –≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url[url] = vacancy_data
                    else:
                        –≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url[url] = vacancy_data

    vacancies = list(–≤–∞–∫–∞–Ω—Å–∏–∏_–ø–æ_url.values())

    if not vacancies:
        msg = "‚ö†Ô∏è –í–∞–∫–∞–Ω—Å–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–Ω–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
        print(msg)
        notifier.send(msg)
        return

    # üìä —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (—Å–Ω–∞—á–∞–ª–∞ –Ω–æ–≤—ã–µ)
    vacancies.sort(
        key=lambda x: parse_dt(x["published_at"]),
        reverse=True,
    )

    # --- CSV ---
    with output_file.open("w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=vacancies[0].keys(),
        )
        writer.writeheader()
        writer.writerows(vacancies)

    msg = (
        "üìÑ –°–±–æ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞–≤–µ—Ä—à—ë–Ω\n"
        f"üîé –ü–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {searches_done}\n"
        f"üìë –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}\n"
        f"üìé –§–∞–π–ª: {output_file.name}"
    )
    print(msg)
    notifier.send(msg, file_path=output_file)


if __name__ == "__main__":
    main()
